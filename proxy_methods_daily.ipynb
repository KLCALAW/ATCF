{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as pc\n",
    "from modified_spectral_method import *\n",
    "from modified_louvain_method import *\n",
    "import cvxpy as cp\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient Calculation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate proxy using the intersection method\n",
    "def calculate_coefficients_intersection_method(prices_data, metadata, index_data, liquid_bucket, date, use_index = False):\n",
    "\n",
    "    company_communities = metadata['Ticker'].to_list()\n",
    "    metadata = metadata.set_index('Ticker')\n",
    "\n",
    "    # prepare the data for the date\n",
    "    prices_data = prices_data.loc[date,:]\n",
    "\n",
    "    # prepare index data for the date\n",
    "    index_data.rename(columns={'AsOf':'Date'}, inplace=True)\n",
    "    index_data['Date'] = pd.to_datetime(index_data['Date'], format='%d/%b/%y')\n",
    "    index_data = index_data.sort_values(by='Date', ascending=True)\n",
    "    index_data = index_data[index_data['Date'] == date]\n",
    "    index_spread = index_data['ConvSpread'].values[0]\n",
    "    # print(f\"Index spread for the date {date} is {index_spread}\")\n",
    "\n",
    "    # prepare the liquid bucket data for the date\n",
    "    liquid_bucket_sector = liquid_bucket['Sector']\n",
    "    liquid_bucket_country = liquid_bucket['Country']\n",
    "    liquid_bucket_ratings = liquid_bucket['Rating']\n",
    "    liquid_bucket_tickers = metadata[(metadata['Sector'] == liquid_bucket_sector) & (metadata['Country'] == liquid_bucket_country) & (metadata['AverageRating'] == liquid_bucket_ratings)].index.to_list()\n",
    "    liquid_bucket_spread = prices_data[liquid_bucket_tickers].mean(axis=0)\n",
    "    print(f\"Liquid bucket spread for the date {date} is {liquid_bucket_spread}\")\n",
    "\n",
    "    if use_index:\n",
    "        global_spread = index_spread\n",
    "    else:\n",
    "        global_spread = liquid_bucket_spread\n",
    "\n",
    "    # create all possible combinations of the buckets\n",
    "    unique_buckets = []\n",
    "\n",
    "    for i in range(len(company_communities)):\n",
    "        bucket = f'{metadata.loc[company_communities[i], 'Sector']}, {metadata.loc[company_communities[i], 'Country']}, {metadata.loc[company_communities[i], 'AverageRating']}'\n",
    "        if bucket not in unique_buckets:\n",
    "            unique_buckets.append(bucket)\n",
    "    if not use_index:\n",
    "        # remove the liquid bucket from the unique buckets\n",
    "        unique_buckets.remove(f'{liquid_bucket_sector}, {liquid_bucket_country}, {liquid_bucket_ratings}')\n",
    "\n",
    "    # prepare the prices data and the indicator matrix\n",
    "    prices_data = prices_data.T.to_numpy()\n",
    "    prices_data = prices_data.reshape(-1, 1)\n",
    "\n",
    "    # create the indicator matrix\n",
    "    indicators = np.zeros((len(company_communities), len(unique_buckets)))\n",
    "    for i in range(len(company_communities)):\n",
    "        # create string for the bucket\n",
    "        bucket = f'{metadata.loc[company_communities[i], 'Sector']}, {metadata.loc[company_communities[i], 'Country']}, {metadata.loc[company_communities[i], 'AverageRating']}'\n",
    "        if bucket in unique_buckets:\n",
    "            j = unique_buckets.index(bucket)\n",
    "            indicators[i, j] = 1\n",
    "\n",
    "    # a_0\n",
    "    a_0 = np.tile(global_spread, (len(company_communities), 1))\n",
    "\n",
    "    # create optimization variables\n",
    "    betas = cp.Variable(shape=(len(unique_buckets), 1))\n",
    "\n",
    "    beta_contributions = indicators @ betas\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(cp.norm(prices_data - a_0 - beta_contributions, \"fro\")**2)\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    problem = cp.Problem(objective)\n",
    "    problem.solve()\n",
    "\n",
    "    # store the coefficients\n",
    "    coefficients = pd.DataFrame({'bucket': unique_buckets, 'Coefficient': betas.value.flatten()})\n",
    "    coefficients = coefficients.set_index('bucket')\n",
    "\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate proxy using the CSRA community method\n",
    "def calculate_proxy_coeff_csra_community(prices_data, communities, metadata, index_data, liquid_bucket, date, use_index = False):\n",
    "    if not isinstance(communities[0], list):\n",
    "        communities = [communities]\n",
    "    coefficients = {}\n",
    "    metadata = metadata.set_index('Ticker')\n",
    "    # prepare the data for the date\n",
    "    prices_data = prices_data.loc[date,:]\n",
    "\n",
    "    # prepare index data for the date\n",
    "    index_data.rename(columns={'AsOf':'Date'}, inplace=True)\n",
    "    index_data['Date'] = pd.to_datetime(index_data['Date'], format='%d/%b/%y')\n",
    "    index_data = index_data.sort_values(by='Date', ascending=True)\n",
    "    index_data = index_data[index_data['Date'] == date]\n",
    "    index_spread = index_data['ConvSpread'].values[0]\n",
    "    # print(f\"Index spread for the date {date} is {index_spread}\")\n",
    "\n",
    "    # prepare the liquid bucket data for the date\n",
    "    liquid_bucket_sector = liquid_bucket['Sector']\n",
    "    liquid_bucket_country = liquid_bucket['Country']\n",
    "    liquid_bucket_ratings = liquid_bucket['Rating']\n",
    "    liquid_bucket_tickers = metadata[(metadata['Sector'] == liquid_bucket_sector) & (metadata['Country'] == liquid_bucket_country) & (metadata['AverageRating'] == liquid_bucket_ratings)].index.to_list()\n",
    "    liquid_bucket_spread = prices_data[liquid_bucket_tickers].mean(axis=0)\n",
    "\n",
    "    # print(f\"Liquid bucket spread for the date {date} is {liquid_bucket_spread}\")\n",
    "\n",
    "    if use_index:\n",
    "        global_spread = index_spread\n",
    "    else:\n",
    "        global_spread = liquid_bucket_spread\n",
    "    \n",
    "    for community_number, community in enumerate(communities):\n",
    "\n",
    "        # prepare the data for the community\n",
    "        prices_data_community = prices_data[community]\n",
    "        metadata_community = metadata.loc[community,:]\n",
    "\n",
    "        sectors_community = metadata_community.loc[community, 'Sector'].unique().tolist()\n",
    "\n",
    "        countries_community = metadata_community.loc[community, 'Country'].unique().tolist()\n",
    "\n",
    "        ratings_community = metadata_community.loc[community, 'AverageRating'].unique().tolist()\n",
    "\n",
    "        # remove the liquid bucket from the community\n",
    "        if not use_index:\n",
    "            if liquid_bucket_sector in sectors_community:\n",
    "                sectors_community.remove(liquid_bucket_sector)\n",
    "            if liquid_bucket_country in countries_community:\n",
    "                countries_community.remove(liquid_bucket_country)\n",
    "            if liquid_bucket_ratings in ratings_community:\n",
    "                ratings_community.remove(liquid_bucket_ratings)\n",
    "\n",
    "        prices_data_community = prices_data_community.T.to_numpy()\n",
    "        prices_data_community = prices_data_community.reshape(-1, 1)\n",
    "\n",
    "        # tranform the data to the log space\n",
    "        prices_data_community_log = np.log(prices_data_community)\n",
    "        # create the masks\n",
    "        mask = np.zeros((prices_data_community.shape[0], len(sectors_community) + len(countries_community) + len(ratings_community)))\n",
    "\n",
    "        for i in range(prices_data_community.shape[0]):\n",
    "            if not use_index:\n",
    "                if metadata_community.loc[community[i], 'Sector'] in sectors_community:\n",
    "                    j = sectors_community.index(metadata_community.loc[community[i], 'Sector'])\n",
    "                    mask[i, j] = 1\n",
    "                if metadata_community.loc[community[i], 'Country'] in countries_community:\n",
    "                    j = len(sectors_community) + countries_community.index(metadata_community.loc[community[i], 'Country']) - 1\n",
    "                    mask[i, j] = 1\n",
    "                if metadata_community.loc[community[i], 'AverageRating'] in ratings_community:\n",
    "                    j = len(sectors_community) + len(countries_community) + ratings_community.index(metadata_community.loc[community[i], 'AverageRating']) - 1\n",
    "                    mask[i, j] = 1\n",
    "\n",
    "\n",
    "            else:    \n",
    "                j = sectors_community.index(metadata_community.loc[community[i], 'Sector'])\n",
    "                mask[i, j] = 1\n",
    "                k = len(sectors_community) + countries_community.index(metadata_community.loc[community[i], 'Country'])  - 1\n",
    "                mask[i, k] = 1\n",
    "                l = len(sectors_community) + len(countries_community) + ratings_community.index(metadata_community.loc[community[i], 'AverageRating']) - 1\n",
    "\n",
    "        # beta_0\n",
    "        beta_0 = np.tile(np.log(global_spread), (prices_data_community.shape[1], 1))\n",
    "\n",
    "        # Define optimization variables\n",
    "        betas = cp.Variable(shape=(len(sectors_community) + len(countries_community) + len(ratings_community), 1))\n",
    "\n",
    "        beta_contributions = mask @ betas\n",
    "\n",
    "        # Define the objective function\n",
    "        objective = cp.Minimize(cp.norm(prices_data_community_log - beta_0 -  beta_contributions, \"fro\")**2)\n",
    "\n",
    "\n",
    "        # Solve the optimization problem\n",
    "        problem = cp.Problem(objective)\n",
    "        problem.solve()\n",
    "\n",
    "        # store the coefficients\n",
    "        sector_betas = betas.value[0:len(sectors_community)]\n",
    "        country_betas = betas.value[len(sectors_community): len(sectors_community) + len(countries_community)]\n",
    "        rating_betas = betas.value[len(sectors_community) + len(countries_community):]\n",
    "\n",
    "        sectors_df = pd.DataFrame({'Name': sectors_community, 'Coefficient': sector_betas.flatten(), 'Type': 'Sector'},)\n",
    "        countries_df = pd.DataFrame({'Name': countries_community, 'Coefficient': country_betas.flatten(), 'Type': 'Country'})\n",
    "        ratings_df = pd.DataFrame({'Name': ratings_community, 'Coefficient': rating_betas.flatten(), 'Type': 'Rating'}) \n",
    "\n",
    "        # Combine DataFrames\n",
    "        coefficients_df = pd.concat([sectors_df, countries_df, ratings_df], ignore_index=True)\n",
    "        coefficients_df = coefficients_df.set_index('Name')\n",
    "        coefficients[f'community_{community_number+1}'] = coefficients_df\n",
    "    \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proxy Calculation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proxy_intersection_method(ticker, metadata, coefficients, prices_data, index_data, liquid_bucket, date, use_index = False):\n",
    "    metadata = metadata.set_index('Ticker')\n",
    "    # prepare the data for the date\n",
    "    prices_data = prices_data.loc[date,:]\n",
    "\n",
    "    # prepare index data for the date\n",
    "    index_data.rename(columns={'AsOf':'Date'}, inplace=True)\n",
    "    index_data['Date'] = pd.to_datetime(index_data['Date'], format='%d/%b/%y')\n",
    "    index_data = index_data.sort_values(by='Date', ascending=True)\n",
    "    index_data = index_data[index_data['Date'] == date]\n",
    "    index_spread = index_data['ConvSpread'].values[0]\n",
    "    # print(f\"Index spread for the date {date} is {index_spread}\")\n",
    "\n",
    "    # prepare the liquid bucket data for the date\n",
    "    liquid_bucket_sector = liquid_bucket['Sector']\n",
    "    liquid_bucket_country = liquid_bucket['Country']\n",
    "    liquid_bucket_ratings = liquid_bucket['Rating']\n",
    "    liquid_bucket_tickers = metadata[(metadata['Sector'] == liquid_bucket_sector) & (metadata['Country'] == liquid_bucket_country) & (metadata['AverageRating'] == liquid_bucket_ratings)].index.to_list()\n",
    "    liquid_bucket_spread = prices_data[liquid_bucket_tickers].mean(axis=0)\n",
    "    # print(f\"Liquid bucket spread for the date {date} is {liquid_bucket_spread}\")\n",
    "\n",
    "    if use_index:\n",
    "        global_spread = index_spread\n",
    "    else:\n",
    "        global_spread = liquid_bucket_spread\n",
    "    company_bucket = f'{metadata.loc[ticker, 'Sector']}, {metadata.loc[ticker, 'Country']}, {metadata.loc[ticker, 'AverageRating']}'\n",
    "\n",
    "    if company_bucket not in coefficients.index:\n",
    "        print(f\"Bucket not found for Company {ticker} \")\n",
    "        return global_spread\n",
    "    else:\n",
    "        print(f\"Bucket FOUND for Company {ticker} \")\n",
    "        coefficient = coefficients.loc[company_bucket, 'Coefficient']\n",
    "\n",
    "        proxy = coefficient + global_spread\n",
    "\n",
    "    return proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proxy_csra_community(ticker,  metadata, coefficients, ticker_community, prices_data, index_data, liquid_bucket, date, use_index = False):\n",
    "    metadata = metadata.set_index('Ticker')\n",
    "    # prepare the data for the date\n",
    "    prices_data = prices_data.loc[date,:]\n",
    "\n",
    "    # prepare index data for the date\n",
    "    index_data.rename(columns={'AsOf':'Date'}, inplace=True)\n",
    "    index_data['Date'] = pd.to_datetime(index_data['Date'], format='%d/%b/%y')\n",
    "    index_data = index_data.sort_values(by='Date', ascending=True)\n",
    "    index_data = index_data[index_data['Date'] == date]\n",
    "    index_spread = index_data['ConvSpread'].values[0]\n",
    "    # print(f\"Index spread for the date {date} is {index_spread}\")\n",
    "\n",
    "    # prepare the liquid bucket data for the date\n",
    "    liquid_bucket_sector = liquid_bucket['Sector']\n",
    "    liquid_bucket_country = liquid_bucket['Country']\n",
    "    liquid_bucket_ratings = liquid_bucket['Rating']\n",
    "    liquid_bucket_tickers = metadata[(metadata['Sector'] == liquid_bucket_sector) & (metadata['Country'] == liquid_bucket_country) & (metadata['AverageRating'] == liquid_bucket_ratings)].index.to_list()\n",
    "    liquid_bucket_spread = prices_data[liquid_bucket_tickers].mean(axis=0)\n",
    "    # print(f\"Liquid bucket spread for the date {date} is {liquid_bucket_spread}\")\n",
    "\n",
    "    if use_index:\n",
    "        global_spread = np.log(index_spread)\n",
    "    else:\n",
    "        global_spread = np.log(liquid_bucket_spread)\n",
    "\n",
    "    company_community = f'community_{ticker_community}'\n",
    "    coefficients_ticker_community = coefficients[company_community]\n",
    "\n",
    "    # get the coefficients for the sector, country and rating\n",
    "    if metadata.loc[ticker, 'Sector'] in coefficients_ticker_community.index:\n",
    "        sector_coefficient = coefficients_ticker_community.loc[metadata.loc[ticker, 'Sector'], 'Coefficient']\n",
    "    else:\n",
    "        sector_coefficient = 0\n",
    "    \n",
    "    if metadata.loc[ticker, 'Country'] in coefficients_ticker_community.index:\n",
    "        country_coefficient = coefficients_ticker_community.loc[metadata.loc[ticker, 'Country'], 'Coefficient']\n",
    "    else:\n",
    "        country_coefficient = 0\n",
    "\n",
    "    if metadata.loc[ticker, 'AverageRating'] in coefficients_ticker_community.index:\n",
    "        rating_coefficient = coefficients_ticker_community.loc[metadata.loc[ticker, 'AverageRating'], 'Coefficient']\n",
    "    else:\n",
    "        rating_coefficient = 0\n",
    "\n",
    "    proxy_log = sector_coefficient + country_coefficient + rating_coefficient + global_spread\n",
    "\n",
    "    proxy = np.exp(proxy_log)\n",
    "\n",
    "    return proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prices data, index data and metadata \n",
    "prices_data = pd.read_csv('data/reshaped_data.csv')\n",
    "prices_data['Date'] = pd.to_datetime(prices_data['Date'], infer_datetime_format=True)\n",
    "prices_data = prices_data.set_index('Date')\n",
    "\n",
    "index_data = pd.read_csv('ITRAXX-Europe Timeseries 20241127.csv')\n",
    "\n",
    "metadata = pd.read_csv('data/metadata.csv')\n",
    " \n",
    "# perform community detection using the modified spectral method\n",
    "correlation_matrix,T,N,company_names = create_correlation_matrix('data/eur_data_standardized_returns.csv')\n",
    "C_g = calculate_C_g(correlation_matrix, T, N)\n",
    "result_communities, company_communities, modularities = recursive_spectral_method(C_g, correlation_matrix, company_names, min_size=2, modularity_threshold=0.00001)\n",
    "print(f\"number of communities detected:{len(company_communities)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liquid_bucket(metadata, company_communities, ticker_proxy):\n",
    "    \"\"\"\n",
    "    Get the liquid bucket for a given ticker.\n",
    "\n",
    "    Parameters:\n",
    "    - metadata (pd.DataFrame): The metadata dataframe containing ticker information.\n",
    "    - company_communities (list of lists): A list of communities where each community is a list of tickers.\n",
    "    - ticker_proxy (str): The ticker for which to calculate the liquid bucket.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary representing the liquid bucket with keys 'Sector', 'Country', and 'Rating', or None if the ticker is not found.\n",
    "    - int: The community number the ticker belongs to, or None if the ticker is not in any community.\n",
    "    \"\"\"\n",
    "    # Find the community to which the ticker belongs\n",
    "    ticker_community = None\n",
    "    for i, community in enumerate(company_communities):\n",
    "        if ticker_proxy in community:\n",
    "            ticker_community = i + 1\n",
    "            break\n",
    "\n",
    "    if ticker_community is None:\n",
    "        print(f\"Ticker {ticker_proxy} is not part of any community.\")\n",
    "        return None, None\n",
    "\n",
    "    # Extract the row corresponding to the ticker\n",
    "    ticker_data = metadata[metadata['Ticker'] == ticker_proxy]\n",
    "\n",
    "    if ticker_data.empty:\n",
    "        print(f\"Ticker {ticker_proxy} not found in metadata.\")\n",
    "        return None, None\n",
    "\n",
    "    # Create the liquid bucket using the extracted data\n",
    "    liquid_bucket = {\n",
    "        'Sector': ticker_data.iloc[0]['Sector'],\n",
    "        'Country': ticker_data.iloc[0]['Country'],\n",
    "        'Rating': ticker_data.iloc[0]['AverageRating']\n",
    "    }\n",
    "\n",
    "    return liquid_bucket, ticker_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_proxy = 'AEGON'\n",
    "liquid_bucket, community = get_liquid_bucket(metadata, company_communities, ticker_proxy)\n",
    "\n",
    "date = '2015-12-30'\n",
    "date = pd.to_datetime(date, format='%Y-%m-%d') # convert the date to pandas datetime format\n",
    "\n",
    "# get the actual spread for the ticker\n",
    "actual_spread = prices_data.loc[date, ticker_proxy]\n",
    "print(f'Actual spread for the ticker {ticker_proxy} is {actual_spread}')\n",
    "\n",
    "# remove the ticker_proxy from the community data, prices data and metadata\n",
    "company_communities_proxy_method = copy.deepcopy(company_communities)\n",
    "print(company_communities_proxy_method[ticker_community-1])\n",
    "company_communities_proxy_method[ticker_community-1].remove(ticker_proxy)\n",
    "metadata_proxy_method = metadata[metadata['Ticker'] != ticker_proxy]\n",
    "prices_data_proxy_method = prices_data.drop(columns= [ticker_proxy])\n",
    "\n",
    "all_companies = [company for community in company_communities for company in community]\n",
    "all_companies_proxy_method = [company for community in company_communities_proxy_method for company in community]\n",
    "\n",
    "# calculate the coefficients and proxy using the intersection method\n",
    "coefficients_intersection = calculate_coefficients_intersection_method(prices_data_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index = False)\n",
    "proxy_intersection = calculate_proxy_intersection_method(ticker_proxy, metadata, coefficients_intersection, prices_data, index_data, liquid_bucket, date, use_index = False)\n",
    "# print(coefficients)\n",
    "print(f'calculated proxy using the intersection method: {proxy_intersection}')\n",
    "\n",
    "# calculate the coefficients and proxy using the CSRA method without the communities\n",
    "coefficients_csra = calculate_proxy_coeff_csra_community(prices_data_proxy_method, all_companies_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index = True)\n",
    "# for key, value in coefficients.items():\n",
    "#     print(key)\n",
    "#     print(value)\n",
    "#     print(\"\")\n",
    "proxy_csra = calculate_proxy_csra_community(ticker_proxy, metadata, coefficients_csra, 1, prices_data, index_data, liquid_bucket, date, use_index = True)\n",
    "print(f'calculated proxy using the CSRA method: {proxy_csra}')\n",
    "\n",
    "# calculate the coefficients and proxy using the CSRA community method\n",
    "coefficients_csra_community = calculate_proxy_coeff_csra_community(prices_data_proxy_method, company_communities_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index = True)\n",
    "proxy_csra_community = calculate_proxy_csra_community(ticker_proxy, metadata, coefficients_csra_community, ticker_community, prices_data, index_data, liquid_bucket, date, use_index = True)\n",
    "print(f'calculated proxy using the CSRA community method: {proxy_csra_community}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proxies_and_add_to_metadata(metadata, company_communities, prices_data, index_data, liquid_bucket, date):\n",
    "    \"\"\"\n",
    "    Calculates proxy spreads and actual spreads for tickers in metadata and adds them as columns to a copy of metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - metadata: pd.DataFrame, contains metadata including tickers.\n",
    "    - company_communities: list of lists, each inner list is a community containing tickers.\n",
    "    - prices_data: pd.DataFrame, price data with tickers as columns.\n",
    "    - index_data: additional index-related data.\n",
    "    - liquid_bucket: dict, liquid bucket information (e.g., Sector, Country, Rating).\n",
    "    - date: str or pd.Timestamp, the date for which proxies are calculated.\n",
    "\n",
    "    Returns:\n",
    "    - metadata_with_proxies: pd.DataFrame, copy of metadata with calculated proxy and actual spread columns added.\n",
    "    \"\"\"\n",
    "    # Ensure date is in pandas datetime format\n",
    "    date = pd.to_datetime(date, format='%Y-%m-%d')\n",
    "    \n",
    "    # Create a copy of metadata to store results\n",
    "    metadata_with_proxies = metadata.copy()\n",
    "    metadata_with_proxies['ActualSpread'] = None\n",
    "    metadata_with_proxies['ProxyIntersection'] = None\n",
    "    metadata_with_proxies['ProxyCSRA'] = None\n",
    "    metadata_with_proxies['ProxyCSRACommunity'] = None\n",
    "\n",
    "    # Iterate over tickers in metadata\n",
    "    for ticker_proxy in metadata['Ticker']:\n",
    "        print(f\"\\nCalculating proxy for ticker: {ticker_proxy}\")\n",
    "\n",
    "        # Find the community to which the ticker belongs\n",
    "        ticker_community = None\n",
    "        for i, community in enumerate(company_communities):\n",
    "            if ticker_proxy in community:\n",
    "                ticker_community = i + 1\n",
    "                break\n",
    "\n",
    "        # Get the actual spread\n",
    "        actual_spread = prices_data.loc[date, ticker_proxy]\n",
    "        print(f\"Actual spread for {ticker_proxy}: {actual_spread}\")\n",
    "\n",
    "        # Remove the ticker_proxy from the relevant data structures\n",
    "        company_communities_proxy_method = copy.deepcopy(company_communities)\n",
    "        company_communities_proxy_method[ticker_community - 1].remove(ticker_proxy)\n",
    "        metadata_proxy_method = metadata[metadata['Ticker'] != ticker_proxy]\n",
    "        prices_data_proxy_method = prices_data.drop(columns=[ticker_proxy])\n",
    "\n",
    "        # Flatten company communities for proxy method\n",
    "        all_companies_proxy_method = [company for community in company_communities_proxy_method for company in community]\n",
    "\n",
    "        # Calculate proxies using intersection and CSRA methods\n",
    "        try:\n",
    "            coefficients_intersection = calculate_coefficients_intersection_method(\n",
    "                prices_data_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=False\n",
    "            )\n",
    "            proxy_intersection = calculate_proxy_intersection_method(\n",
    "                ticker_proxy, metadata, coefficients_intersection, prices_data, index_data, liquid_bucket, date, use_index=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating proxy using intersection method for {ticker_proxy}: {e}\")\n",
    "            proxy_intersection = None\n",
    "\n",
    "        try:\n",
    "            coefficients_csra = calculate_proxy_coeff_csra_community(\n",
    "                prices_data_proxy_method, all_companies_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=True\n",
    "            )\n",
    "            proxy_csra = calculate_proxy_csra_community(\n",
    "                ticker_proxy, metadata, coefficients_csra, 1, prices_data, index_data, liquid_bucket, date, use_index=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating proxy using CSRA method for {ticker_proxy}: {e}\")\n",
    "            proxy_csra = None\n",
    "\n",
    "        try:\n",
    "            coefficients_csra_community = calculate_proxy_coeff_csra_community(\n",
    "                prices_data_proxy_method, company_communities_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=True\n",
    "            )\n",
    "            proxy_csra_community = calculate_proxy_csra_community(\n",
    "                ticker_proxy, metadata, coefficients_csra_community, ticker_community, prices_data, index_data, liquid_bucket, date, use_index=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating proxy using CSRA community method for {ticker_proxy}: {e}\")\n",
    "            proxy_csra_community = None\n",
    "\n",
    "        # Update the copied metadata with the results\n",
    "        metadata_with_proxies.loc[metadata_with_proxies['Ticker'] == ticker_proxy, 'ActualSpread'] = actual_spread\n",
    "        metadata_with_proxies.loc[metadata_with_proxies['Ticker'] == ticker_proxy, 'ProxyIntersection'] = proxy_intersection\n",
    "        metadata_with_proxies.loc[metadata_with_proxies['Ticker'] == ticker_proxy, 'ProxyCSRA'] = proxy_csra\n",
    "        metadata_with_proxies.loc[metadata_with_proxies['Ticker'] == ticker_proxy, 'ProxyCSRACommunity'] = proxy_csra_community\n",
    "\n",
    "    return metadata_with_proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_with_proxies = calculate_proxies_and_add_to_metadata(metadata, company_communities, prices_data, index_data, liquid_bucket, date)\n",
    "metadata_with_proxies.to_csv('data/metadata_with_proxies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_proxy_time_series_for_ticker(\n",
    "    ticker, metadata, company_communities, prices_data, index_data, liquid_bucket, date_range\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the time series of proxy values for a specific ticker.\n",
    "\n",
    "    Parameters:\n",
    "    - ticker: str, the ticker for which to calculate proxies.\n",
    "    - metadata: pd.DataFrame, metadata including the ticker.\n",
    "    - company_communities: list of lists, each inner list is a community containing tickers.\n",
    "    - prices_data: pd.DataFrame, price data with tickers as columns.\n",
    "    - index_data: additional index-related data.\n",
    "    - liquid_bucket: dict, liquid bucket information (e.g., Sector, Country, Rating).\n",
    "    - date_range: iterable of dates.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, time series of proxy values for the specified ticker.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for date in date_range:\n",
    "        try:\n",
    "            # Ensure the date is in pandas datetime format\n",
    "            date = pd.to_datetime(date)\n",
    "            \n",
    "            # Locate the community for the ticker\n",
    "            ticker_community = None\n",
    "            for i, community in enumerate(company_communities):\n",
    "                if ticker in community:\n",
    "                    ticker_community = i + 1\n",
    "                    break\n",
    "            \n",
    "            # Calculate actual spread\n",
    "            actual_spread = prices_data.loc[date, ticker]\n",
    "            \n",
    "            # Remove the ticker from proxy calculations\n",
    "            company_communities_proxy_method = copy.deepcopy(company_communities)\n",
    "            company_communities_proxy_method[ticker_community - 1].remove(ticker)\n",
    "            metadata_proxy_method = metadata[metadata['Ticker'] != ticker]\n",
    "            prices_data_proxy_method = prices_data.drop(columns=[ticker])\n",
    "            \n",
    "            # Flatten communities\n",
    "            all_companies_proxy_method = [\n",
    "                company for community in company_communities_proxy_method for company in community\n",
    "            ]\n",
    "\n",
    "            # Calculate proxies\n",
    "            proxy_intersection = None\n",
    "            proxy_csra = None\n",
    "            proxy_csra_community = None\n",
    "\n",
    "            try:\n",
    "                coefficients_intersection = calculate_coefficients_intersection_method(\n",
    "                    prices_data_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=False\n",
    "                )\n",
    "                proxy_intersection = calculate_proxy_intersection_method(\n",
    "                    ticker, metadata, coefficients_intersection, prices_data, index_data, liquid_bucket, date, use_index=False\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating intersection proxy for {ticker} on {date}: {e}\")\n",
    "            \n",
    "            try:\n",
    "                coefficients_csra = calculate_proxy_coeff_csra_community(\n",
    "                    prices_data_proxy_method, all_companies_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=True\n",
    "                )\n",
    "                proxy_csra = calculate_proxy_csra_community(\n",
    "                    ticker, metadata, coefficients_csra, 1, prices_data, index_data, liquid_bucket, date, use_index=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating CSRA proxy for {ticker} on {date}: {e}\")\n",
    "            \n",
    "            try:\n",
    "                coefficients_csra_community = calculate_proxy_coeff_csra_community(\n",
    "                    prices_data_proxy_method, company_communities_proxy_method, metadata_proxy_method, index_data, liquid_bucket, date, use_index=True\n",
    "                )\n",
    "                proxy_csra_community = calculate_proxy_csra_community(\n",
    "                    ticker, metadata, coefficients_csra_community, ticker_community, prices_data, index_data, liquid_bucket, date, use_index=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating CSRA community proxy for {ticker} on {date}: {e}\")\n",
    "            \n",
    "            # Append results for this date\n",
    "            results.append({\n",
    "                \"Date\": date,\n",
    "                \"ActualSpread\": actual_spread,\n",
    "                \"ProxyIntersection\": proxy_intersection,\n",
    "                \"ProxyCSRA\": proxy_csra,\n",
    "                \"ProxyCSRACommunity\": proxy_csra_community,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating proxies for {ticker} on {date}: {e}\")\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=\"2015-01-01\", end=\"2015-12-31\", freq=\"D\")\n",
    "ticker_proxy = \"ALZSE\"\n",
    "proxy_time_series = calculate_proxy_time_series_for_ticker(\n",
    "    ticker = ticker_proxy, \n",
    "    metadata=metadata, \n",
    "    company_communities=company_communities, \n",
    "    prices_data=prices_data, \n",
    "    index_data=index_data, \n",
    "    liquid_bucket=get_liquid_bucket(metadata, company_communities, ticker_proxy)[0], \n",
    "    date_range=date_range\n",
    ")\n",
    "\n",
    "print(proxy_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time series of the proxy methods\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot each proxy method and actual spread\n",
    "plt.plot(proxy_time_series['Date'], proxy_time_series['ActualSpread'], label='Actual Spread')\n",
    "plt.plot(proxy_time_series['Date'], proxy_time_series['ProxyIntersection'], label='Proxy Intersection')\n",
    "plt.plot(proxy_time_series['Date'], proxy_time_series['ProxyCSRA'], label='Proxy CSRA')\n",
    "plt.plot(proxy_time_series['Date'], proxy_time_series['ProxyCSRACommunity'], label='Proxy CSRA Community')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title(f\"Proxy Methods for Ticker Over Time\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"Spread\", fontsize=12)\n",
    "\n",
    "# Adding grid and legend\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(loc=\"upper right\", fontsize=10)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(actual_spread, proxy_spread):\n",
    "    \"\"\"\n",
    "    Calculate the RMSE between actual spreads and proxy spreads.\n",
    "\n",
    "    Parameters:\n",
    "    - actual_spread (pd.Series or np.array): The actual spreads (\\( \\hat{S}_j \\)).\n",
    "    - proxy_spread (pd.Series or np.array): The proxy spreads (\\( S_j^{proxy} \\)).\n",
    "\n",
    "    Returns:\n",
    "    - float: The RMSE value.\n",
    "    \"\"\"\n",
    "    # Ensure the inputs are numpy arrays\n",
    "    actual_spread = np.array(actual_spread)\n",
    "    proxy_spread = np.array(proxy_spread)\n",
    "    \n",
    "    # Calculate the squared differences\n",
    "    squared_differences = (actual_spread - proxy_spread) ** 2\n",
    "    \n",
    "    # Calculate the mean of squared differences\n",
    "    mean_squared_error = np.mean(squared_differences)\n",
    "    \n",
    "    # Return the square root of the mean squared error\n",
    "    return np.sqrt(mean_squared_error)\n",
    "\n",
    "# Example usage with proxy_time_series DataFrame\n",
    "rmse_csra = calculate_rmse(proxy_time_series['ActualSpread'], proxy_time_series['ProxyCSRA'])\n",
    "rmse_csra_community = calculate_rmse(proxy_time_series['ActualSpread'], proxy_time_series['ProxyCSRACommunity'])\n",
    "\n",
    "print(f\"RMSE for Proxy CSRA: {rmse_csra}\")\n",
    "print(f\"RMSE for Proxy CSRA Community: {rmse_csra_community}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
